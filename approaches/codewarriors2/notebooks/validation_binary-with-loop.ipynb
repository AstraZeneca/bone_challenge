{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ebfba5-04c4-44d7-8bee-9870a7e67e14",
   "metadata": {},
   "source": [
    "# Validation notebook for ResNet binary classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3b573-6993-4255-9b3b-2bfb761abded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "sys.path.append('..')\n",
    "from data_utils.dataset import BoneSlicesDatasetPrev\n",
    "from training.validation_metrics import get_true_and_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa4e6d-f4a3-45e2-83ea-35408c553fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def _calculate_score(pred_slice_num, gt_slice_num):\n",
    "    \"\"\"Returns the survival function a single-sided normal distribution with stddev=3.\"\"\"\n",
    "    diff = abs(pred_slice_num - gt_slice_num)\n",
    "    return 2 * norm.sf(diff, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f979edc-89d2-44ca-aab2-c8171d783c67",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "---\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c873749-4b55-45ad-a5dc-6df119828ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else 'cpu'\n",
    "#MODEL_PATH = 'training/resnet_18_6/saved_models/Iteration_1/model_20240514_134211_11'\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "VALIDATION_EXAMPLES_FILE = '10folds/5_fold/validation_examples.csv'\n",
    "TRAINING_EXAMPLES_FILE = '10folds/5_fold/training_examples.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91bb7f-5740-4c13-b2fc-a323c9ef991e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b446de-9fa0-41ba-9e34-7bd5ad82fb7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7baa11-9ea5-406c-a8ef-58f7d2cec81a",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "---\n",
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c2f71-80e6-435c-bdad-567f626d4b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "# Changing last classificator layer from 1000 classes to 2\n",
    "resnet.fc = nn.Linear(512, 2)\n",
    "\n",
    "# Changing 3 channels into 1 (monochromatic image)\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# Load model\n",
    "resnet.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Evaluation state (not computing gradients) and sending to DEVICE\n",
    "resnet.eval()\n",
    "resnet.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8553f8f-2963-45d5-82c1-e882866c1fd3",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "---\n",
    "## Validation dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb90b14-eb95-4e71-b16a-5ffa7b79a3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_examples = list(pd.read_csv(VALIDATION_EXAMPLES_FILE)['Image Name'])\n",
    "training_examples = list(pd.read_csv(TRAINING_EXAMPLES_FILE)['Image Name'])\n",
    "\n",
    "train_ds = BoneSlicesDatasetPrev(json_config_filepath = 'data_utils/config_binary_z.json', transform=transforms)\n",
    "valid_ds = BoneSlicesDatasetPrev(json_config_filepath = 'data_utils/config_binary_z.json')\n",
    "\n",
    "train_ds.subset_by_image_name(training_examples)\n",
    "valid_ds.subset_by_image_name(validation_examples)\n",
    "print(f\"Size of the validation dataset: {len(valid_ds.metadata['Image Name'])}\")\n",
    "print(f\"Size of the validation dataset: {len(valid_ds)}\")\n",
    "print(f\"Size of the training dataset: {len(train_ds.metadata['Image Name'])}\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5e8fe-91bb-4235-bb00-08652588b9f1",
   "metadata": {},
   "source": [
    "## LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207b7b9-dde4-448f-ac60-3e3b6e0cd250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import cv2\n",
    "mean_all_scores = []\n",
    "mean_all_scores_filter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc11b9-a639-43bd-9dbb-a70e14802dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wrongly_classified = []\n",
    "mean_scores = []\n",
    "mean_scores_filter = []\n",
    "for i in range(EPOCHS):\n",
    "    print(f\" ############## EPOCH {i} ###################\")\n",
    "    MODEL_PATH = f'training/resnet_18_6_splits/fold5/saved_models/Iteration_1/model_20240519_195735_{i}'\n",
    "    resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    # Changing last classificator layer from 1000 classes to 2\n",
    "    resnet.fc = nn.Linear(512, 2)\n",
    "\n",
    "    # Changing 3 channels into 1 (monochromatic image)\n",
    "    resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "    # Load model\n",
    "    resnet.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "    # Evaluation state (not computing gradients) and sending to DEVICE\n",
    "    resnet.eval()\n",
    "    resnet.to(DEVICE)\n",
    "\n",
    "    validation_examples = list(pd.read_csv(VALIDATION_EXAMPLES_FILE)['Image Name'])\n",
    "    training_examples = list(pd.read_csv(TRAINING_EXAMPLES_FILE)['Image Name'])\n",
    "\n",
    "    train_ds = BoneSlicesDatasetPrev(json_config_filepath = 'data_utils/config_binary_z.json', transform=transforms)\n",
    "    valid_ds = BoneSlicesDatasetPrev(json_config_filepath = 'data_utils/config_binary_z.json')\n",
    "\n",
    "    train_ds.subset_by_image_name(training_examples)\n",
    "    valid_ds.subset_by_image_name(validation_examples)\n",
    "    # print(f\"Size of the validation dataset: {len(valid_ds.metadata['Image Name'])}\")\n",
    "    # print(f\"Size of the validation dataset: {len(valid_ds)}\")\n",
    "    # print(f\"Size of the training dataset: {len(train_ds.metadata['Image Name'])}\")\n",
    "\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    start = time.time()\n",
    "    true_labels, predicted_labels = get_true_and_predicted_labels(resnet, val_dl, DEVICE)\n",
    "    end = time.time()\n",
    "    print(f\"Execution time: {end - start}\")\n",
    "\n",
    "    n_wrongly_classifed = (predicted_labels != true_labels).sum().item()\n",
    "    wrongly_classified.append(n_wrongly_classifed)\n",
    "    print(f\"Number of wrongly classified slices: {n_wrongly_classifed}\")\n",
    "\n",
    "    report = classification_report(true_labels, predicted_labels, digits=4)\n",
    "    result = valid_ds.metadata\n",
    "    result['predicted_labels'] = predicted_labels\n",
    "    result['true_labels'] = true_labels\n",
    "    result\n",
    "\n",
    "    scores = []\n",
    "    scores_filter = []\n",
    "    for img in result.groupby(['Image Name']):\n",
    "        predicted = np.asarray(img[1]['predicted_labels'])\n",
    "        true = img[1]['true_labels']\n",
    "        growth_plate_index = img[1]['Growth Plate Index']\n",
    "        # applying morphological closing \n",
    "        predicted_filter = cv2.morphologyEx(predicted, cv2.MORPH_CLOSE, np.ones((5,1)))\n",
    "        predicted_index = (predicted==0).argmax(axis=0)\n",
    "        predicted_filter_index = (predicted_filter==0).argmax(axis=0)\n",
    "        true_index = growth_plate_index.iloc[0]\n",
    "        scores.append(_calculate_score(predicted_index, true_index))\n",
    "        scores_filter.append(_calculate_score(predicted_filter_index, true_index))\n",
    "    scores = np.array(scores)\n",
    "    scores_filter = np.array(scores_filter)\n",
    "    print(f\"Mean score without filtering: {scores.mean()}\")\n",
    "    mean_scores.append(scores.mean())\n",
    "    print(f\"Mean scores with filtering: {scores_filter.mean()}\")\n",
    "    mean_scores_filter.append(scores_filter.mean())\n",
    "    \n",
    "mean_all_scores.append(mean_scores)\n",
    "mean_all_scores_filter.append(mean_scores_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ed14f-8ebd-4ac5-910e-7744af6cb9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(1,EPOCHS, EPOCHS)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(x, wrongly_classified, '.-')\n",
    "ax2.plot(x, mean_scores, '.--', color='darkblue', label='Without filtering')\n",
    "ax2.plot(x, mean_scores_filter, '.:', color='coral', label='With filtering (closing)')\n",
    "\n",
    "ax1.set_ylabel('Wrongly classified')\n",
    "ax2.set_ylabel('Mean scores')\n",
    "ax2.set_xlabel('EPOCH')\n",
    "ax2.set_xticks(x)\n",
    "ax2.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad03ec5-962a-401d-abe4-e71c1b978323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mean_all_scores = mean_all_scores[1:]\n",
    "mean_all_scores_filter = mean_all_scores_filter[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b2dda-e51e-421a-b094-94e24a5bf872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mean_all_scores[0] = mean_all_scores[0][0:20]\n",
    "mean_all_scores_filter[0] = mean_all_scores_filter[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76120f4-ca86-435e-b27d-cc33415306f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_all_arr = np.asarray(mean_all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be303be9-fae5-419e-bc32-b66f057471d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_all_filt_arr = np.asarray(mean_all_scores_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061cdd8-a2a2-404f-9cf5-f1fd68194f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_all_filt_arr_mean = np.mean(mean_all_filt_arr, axis=0)\n",
    "mean_all_arr_mean = np.mean(mean_all_arr, axis=0)\n",
    "mean_all_filt_arr_std= np.std(mean_all_filt_arr, axis=0)\n",
    "mean_all_arr_std= np.std(mean_all_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e292d6-755c-4d5a-b4e3-f56cb259c542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(1,EPOCHS, EPOCHS)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(16,8))\n",
    "\n",
    "ax1.plot(x, mean_all_arr_mean, '.--', color='darkblue', label='Without filtering')\n",
    "ax1.plot(x, mean_all_filt_arr_mean, '.:', color='coral', label='With filtering (closing)')\n",
    "\n",
    "ax2.plot(x, mean_all_arr_std, '.--', color='darkblue', label='Without filtering')\n",
    "ax2.plot(x, mean_all_filt_arr_std, '.:', color='coral', label='With filtering (closing)')\n",
    "\n",
    "ax1.set_ylabel('MEAN')\n",
    "ax2.set_ylabel('STD')\n",
    "ax2.set_xlabel('EPOCH')\n",
    "ax2.set_xticks(x)\n",
    "ax1.legend(loc='best')\n",
    "ax2.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79432beb-b0c0-4cc8-994b-6f536116450b",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# Results (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38076c-a83f-4c1b-bf2e-b7296f35436a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "true_labels, predicted_labels = get_true_and_predicted_labels(resnet, val_dl, DEVICE)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ad720-6546-4296-93eb-abf7d2638f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647fca2-e892-4821-a541-caa8fbc32b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63394c-24c3-4c2f-904c-1599eef0d833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_wrongly_classifed = (predicted_labels != true_labels).sum().item()\n",
    "print(f\"Number of wrongly classified slices: {n_wrongly_classifed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384e4116-b1c5-4fbd-ab4b-081eb90aeec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = (predicted_labels != true_labels).nonzero()\n",
    "\n",
    "fig, ax = plt.subplots(nrows = n_wrongly_classifed//5+1, ncols = 5, figsize = (40,40))\n",
    "for i, idx in enumerate(indices):\n",
    "    idx = idx.item()\n",
    "    data, label = valid_ds[idx]\n",
    "    ax[i//5, i%5].imshow(data.permute(2,1,0), cmap='gray')\n",
    "    image_name = valid_ds.metadata.iloc[idx]['Image Name']\n",
    "    slice_index = valid_ds.metadata.iloc[idx]['Slice Index']\n",
    "    growth_plate_index = valid_ds.metadata.iloc[idx]['Growth Plate Index']\n",
    "    ax[i//5, i%5].title.set_text(f'image: {image_name}, slice: {slice_index}, growth plate {growth_plate_index}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4968b6-172e-47fe-a12e-282c90cc3336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(true_labels, predicted_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b858b-71b3-4462-a6cc-2fb43c5260ba",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# Competition score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff667db-6674-47d5-baef-976b2a8e2950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = valid_ds.metadata\n",
    "result['predicted_labels'] = predicted_labels\n",
    "result['true_labels'] = true_labels\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f9a25-04cd-40d2-99fa-24f4749738cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Julka\n",
    "predicted = []\n",
    "for img in result.groupby(['Image Name']):\n",
    "    predicted.append(np.asarray(img[1]['predicted_labels']))\n",
    "    #growth_plate_index = img[1]['Growth Plate Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ec2b9-31d7-4032-af95-367196c3fe3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "pred = predicted[8]\n",
    "pred_new = cv2.dilate(pred, np.ones((5, 1), np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a6184-acf3-440a-870b-540d16de772d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f280c03-9f13-4f90-b623-9b9d34b78c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "prediction_pair = []\n",
    "print('Prediction | True')\n",
    "for img in result.groupby(['Image Name']):\n",
    "    predicted = np.asarray(img[1]['predicted_labels'])\n",
    "    true = img[1]['true_labels']\n",
    "    growth_plate_index = img[1]['Growth Plate Index']\n",
    "    # applying morphological closing \n",
    "    #predicted = cv2.morphologyEx(predicted, cv2.MORPH_CLOSE, np.ones((3,1)))\n",
    "    predicted_index = (predicted==0).argmax(axis=0)\n",
    "    true_index = growth_plate_index.iloc[0]\n",
    "    scores.append(_calculate_score(predicted_index, true_index))\n",
    "    prediction_pair.append((predicted_index, true_index))\n",
    "    print(f\"{predicted_index}  |  {true_index}\")\n",
    "\n",
    "scores = np.array(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cfade-94ec-4f59-8265-540b023c6b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a295a-f171-4afb-8b90-5eed4e7ffbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630e1eb-9eef-426e-b7ea-8956d80e7327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 (Code Warriors)",
   "language": "python",
   "name": "code-warriors"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
