{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ebfba5-04c4-44d7-8bee-9870a7e67e14",
   "metadata": {},
   "source": [
    "# Validation notebook for ResNet binary classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3b573-6993-4255-9b3b-2bfb761abded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "sys.path.append('..')\n",
    "from data_utils.dataset import BoneSlicesDatasetPrev\n",
    "from training.validation_metrics import get_true_and_predicted_labels, get_predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f979edc-89d2-44ca-aab2-c8171d783c67",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "---\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c873749-4b55-45ad-a5dc-6df119828ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else 'cpu'\n",
    "MODEL_PATH = 'training/resnet_18_6_all/saved_models/Iteration_1/model_20240520_093559_14'\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "#VALIDATION_EXAMPLES_FILE = 'validation_examples.csv'\n",
    "VALIDATION_EXAMPLES_FILE = 'test.csv'\n",
    "#TRAINING_EXAMPLES_FILE = 'training_examples.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91bb7f-5740-4c13-b2fc-a323c9ef991e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b446de-9fa0-41ba-9e34-7bd5ad82fb7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7baa11-9ea5-406c-a8ef-58f7d2cec81a",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "---\n",
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c2f71-80e6-435c-bdad-567f626d4b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "# Changing last classificator layer from 1000 classes to 2\n",
    "resnet.fc = nn.Linear(512, 2)\n",
    "\n",
    "# Changing 3 channels into 1 (monochromatic image)\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# Load model\n",
    "resnet.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# Evaluation state (not computing gradients) and sending to DEVICE\n",
    "resnet.eval()\n",
    "resnet.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8553f8f-2963-45d5-82c1-e882866c1fd3",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "---\n",
    "## Validation dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb90b14-eb95-4e71-b16a-5ffa7b79a3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_examples = list(pd.read_csv(VALIDATION_EXAMPLES_FILE)['Image Name'])\n",
    "#training_examples = list(pd.read_csv(TRAINING_EXAMPLES_FILE)['Image Name'])\n",
    "\n",
    "#train_ds = BoneSlicesDatasetPrev(json_config_filepath = 'data_utils/config_binary_z.json', transform=transforms)\n",
    "valid_ds = BoneSlicesDatasetPrev(json_config_filepath = 'data_utils/config_binary_test.json')\n",
    "\n",
    "\n",
    "#train_ds.subset_by_image_name(training_examples)\n",
    "valid_ds.subset_by_image_name(validation_examples)\n",
    "print(f\"Size of the validation dataset: {len(valid_ds.metadata['Image Name'])}\")\n",
    "print(f\"Size of the validation dataset: {len(valid_ds)}\")\n",
    "#print(f\"Size of the training dataset: {len(train_ds.metadata['Image Name'])}\")\n",
    "\n",
    "#train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79432beb-b0c0-4cc8-994b-6f536116450b",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# Results (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38076c-a83f-4c1b-bf2e-b7296f35436a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#true_labels, predicted_labels = get_true_and_predicted_labels(resnet, val_dl, DEVICE)\n",
    "predicted_labels = get_predicted_labels(resnet, val_dl, DEVICE)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ad720-6546-4296-93eb-abf7d2638f92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647fca2-e892-4821-a541-caa8fbc32b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63394c-24c3-4c2f-904c-1599eef0d833",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_wrongly_classifed = (predicted_labels != true_labels).sum().item()\n",
    "print(f\"Number of wrongly classified slices: {n_wrongly_classifed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384e4116-b1c5-4fbd-ab4b-081eb90aeec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = (predicted_labels != true_labels).nonzero()\n",
    "\n",
    "fig, ax = plt.subplots(nrows = n_wrongly_classifed//5+1, ncols = 5, figsize = (40,40))\n",
    "for i, idx in enumerate(indices):\n",
    "    idx = idx.item()\n",
    "    data, label = valid_ds[idx]\n",
    "    ax[i//5, i%5].imshow(data.permute(2,1,0), cmap='gray')\n",
    "    image_name = valid_ds.metadata.iloc[idx]['Image Name']\n",
    "    slice_index = valid_ds.metadata.iloc[idx]['Slice Index']\n",
    "    growth_plate_index = valid_ds.metadata.iloc[idx]['Growth Plate Index']\n",
    "    ax[i//5, i%5].title.set_text(f'image: {image_name}, slice: {slice_index}, growth plate {growth_plate_index}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4968b6-172e-47fe-a12e-282c90cc3336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(true_labels, predicted_labels, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b858b-71b3-4462-a6cc-2fb43c5260ba",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# Competition score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff667db-6674-47d5-baef-976b2a8e2950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = valid_ds.metadata\n",
    "result['predicted_labels'] = predicted_labels\n",
    "#result['true_labels'] = true_labels\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f9a25-04cd-40d2-99fa-24f4749738cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Julka\n",
    "predicted = []\n",
    "for img in result.groupby(['Image Name']):\n",
    "    predicted.append(np.asarray(img[1]['predicted_labels']))\n",
    "    #growth_plate_index = img[1]['Growth Plate Index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ec2b9-31d7-4032-af95-367196c3fe3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "pred = predicted[8]\n",
    "pred_new = cv2.dilate(pred, np.ones((5, 1), np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a6184-acf3-440a-870b-540d16de772d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa4e6d-f4a3-45e2-83ea-35408c553fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def _calculate_score(pred_slice_num, gt_slice_num):\n",
    "    \"\"\"Returns the survival function a single-sided normal distribution with stddev=3.\"\"\"\n",
    "    diff = abs(pred_slice_num - gt_slice_num)\n",
    "    return 2 * norm.sf(diff, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db23ee-43a5-44c2-b9c2-97881f636d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f280c03-9f13-4f90-b623-9b9d34b78c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scores = []\n",
    "#prediction_pair = []\n",
    "#print('Prediction | True')\n",
    "all_pred = []\n",
    "all_pred_filtr = []\n",
    "for img in result.groupby(['Image Name']):\n",
    "    predicted = np.asarray(img[1]['predicted_labels'])\n",
    "    #true = img[1]['true_labels']\n",
    "    #growth_plate_index = img[1]['Growth Plate Index']\n",
    "    # applying morphological closing \n",
    "    predicted_filter = cv2.morphologyEx(predicted, cv2.MORPH_CLOSE, np.ones((5,1)))\n",
    "    predicted_filter_index = (predicted_filter==0).argmax(axis=0)\n",
    "    predicted_index = (predicted==0).argmax(axis=0)\n",
    "    #true_index = growth_plate_index.iloc[0]\n",
    "    # print(predicted, end = '\\n\\n\\n')\n",
    "    all_pred.append(predicted_index)\n",
    "    all_pred_filtr.append(predicted_filter_index)\n",
    "    # print(np.array(predicted==0, dtype = np.float16))\n",
    "    # print(np.array(predicted==0, dtype = np.float16).argmax(axis=0))\n",
    "    # print('pred164', predicted[174])\n",
    "    # print(\"Predicted:\", predicted_index)\n",
    "    # print(\"True:\", true_index)\n",
    "   #break\n",
    "    \n",
    "    # scores.append(_calculate_score(predicted_index, true_index))\n",
    "    # prediction_pair.append((predicted_index, true_index))\n",
    "    # print(f\"{predicted_index}  |  {true_index}\")\n",
    "\n",
    "# scores = np.array(scores)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b710f89-09d4-4cc1-9422-1efcb0e65676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858a657-0a56-4026-b355-ebea1016285b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_pred_filtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f0b86-7d04-496f-aa15-cea5a994089e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "7*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826cfade-94ec-4f59-8265-540b023c6b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8732957a-e932-4d8f-8b5b-c42d215cd512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a295a-f171-4afb-8b90-5eed4e7ffbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246640c9-94bc-47c9-ac91-7558383b2438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818cae0c-1ec7-4527-8693-ba8f18765ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_hat = np.array((list(zip(*prediction_pair))[0]))\n",
    "y = np.array((list(zip(*prediction_pair))[1]))\n",
    "print(f\"Mean absolute error: {mean_absolute_error(y_hat, y)}\")\n",
    "\n",
    "plt.hist(y_hat - y, bins = 15)\n",
    "plt.xlabel(\"predicted_index - true_index\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of the results\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 (Code Warriors)",
   "language": "python",
   "name": "code-warriors"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
